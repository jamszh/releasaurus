"use strict";(self.webpackChunkreleasaurus=self.webpackChunkreleasaurus||[]).push([[24],{9844:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/v2.0.1-pytorch","metadata":{"permalink":"/releaseaurus/releases/v2.0.1-pytorch","editUrl":"https://github.com/jamszh/releasaurus/tree/main/releases/v2.0.1-pytorch.mdx","source":"@site/releases/v2.0.1-pytorch.mdx","title":"v2.0.1-pytorch","description":"This release is meant to fix the following issues (regressions / silent correctness):","date":"2023-05-08T19:55:19.000Z","formattedDate":"May 8, 2023","tags":[{"label":"pytorch","permalink":"/releaseaurus/releases/tags/pytorch"}],"readingTime":2.19,"hasTruncateMarker":false,"authors":[{"name":"drisspg","url":"https://github.com/drisspg","image_url":"https://avatars.githubusercontent.com/u/32754868?v=4","imageURL":"https://avatars.githubusercontent.com/u/32754868?v=4"}],"frontMatter":{"title":"v2.0.1-pytorch","date":"2023-05-08T19:55:19.000Z","tags":["pytorch"],"authors":{"name":"drisspg","url":"https://github.com/drisspg","image_url":"https://avatars.githubusercontent.com/u/32754868?v=4","imageURL":"https://avatars.githubusercontent.com/u/32754868?v=4"}}},"content":"This release is meant to fix the following issues (regressions / silent correctness):\\r\\n* Fix `_canonical_mask` throws warning when bool masks passed as input to TransformerEncoder/TransformerDecoder (#96009, #96286) \\r\\n* Fix Embedding bag max_norm=-1 causes leaf Variable that requires grad is being used in an in-place operation #95980\\r\\n* Fix type hint for torch.Tensor.grad_fn, which can be a torch.autograd.graph.Node or None. #96804\\r\\n* Can\u2019t convert float to int when the input is a scalar np.ndarray. #97696\\r\\n* Revisit torch._six.string_classes removal  #97863\\r\\n* Fix module backward pre-hooks to actually update gradient #97983\\r\\n* Fix load_sharded_optimizer_state_dict error on multi node #98063\\r\\n* Warn once for TypedStorage deprecation #98777\\r\\n* cuDNN V8 API, Fix incorrect use of emplace in the benchmark cache #97838\\r\\n### Torch.compile:\\r\\n* Add support for Modules with custom __getitem__ method to torch.compile #97932\\r\\n* Fix improper guards with on list variables. #97862\\r\\n* Fix Sequential nn module with duplicated submodule #98880\\r\\n### Distributed:\\r\\n*   Fix distributed_c10d\'s handling of custom backends #95072\\r\\n*   Fix MPI backend not properly initialized #98545\\r\\n### NN_frontend:\\r\\n* Update Multi-Head Attention\'s doc string #97046\\r\\n* Fix incorrect behavior of `is_causal` paremeter for torch.nn.TransformerEncoderLayer.forward #97214\\r\\n* Fix error for SDPA on sm86 and sm89 hardware #99105\\r\\n* Fix nn.MultiheadAttention mask handling  #98375\\r\\n### DataLoader:\\r\\n* Fix regression for pin_memory recursion when operating on bytes #97737\\r\\n* Fix collation logic #97789 \\r\\n* Fix Ppotentially backwards incompatible change with DataLoader and is_shardable Datapipes #97287\\r\\n### MPS:\\r\\n* Fix LayerNorm crash when input is in float16 #96208\\r\\n* Add support for cumsum on int64 input  #96733\\r\\n* Fix issue with setting BatchNorm to non-trainable #98794\\r\\n### Functorch:\\r\\n* Fix Segmentation Fault for vmaped function accessing BatchedTensor.data #97237\\r\\n* Fix index_select support when dim is negative [#97916](https://github.com/pytorch/pytorch/pull/97916)\\r\\n* Improve docs for autograd.Function support #98020\\r\\n* Fix Exception thrown when running Migration guide example for jacrev #97746\\r\\n### Releng:\\r\\n* Fix Convolutions for CUDA-11.8 wheel builds #99451\\r\\n* Fix Import torchaudio + torch.compile crashes on exit #96231\\r\\n* Linux aarch64 wheels are missing the mkldnn+acl backend support  - [https://github.com/pytorch/builder/commit/54931c264ed3e7346899f547a272c4329cc8933b](https://github.com/pytorch/builder/commit/54931c264ed3e7346899f547a272c4329cc8933b)\\r\\n* Linux aarch64 torchtext 0.15.1 wheels are missing for aarch64_linux platform - [https://github.com/pytorch/builder/issues/1375](https://github.com/pytorch/builder/issues/1375)\\r\\n* Enable ROCm 5.4.2 manywheel and python 3.11 builds #99552\\r\\n* PyTorch cannot be installed at the same time as numpy in a conda env on osx-64 / Python 3.11 #97031\\r\\n* Illegal instruction (core dumped) on Raspberry Pi 4.0 8gb  - https://github.com/pytorch/builder/pull/1370\\r\\n### Torch.optim:\\r\\n*  Fix fused AdamW causes NaN loss #95847\\r\\n* Fix Fused AdamW has worse loss than Apex and unfused AdamW for fp16/AMP #98620\\r\\n\\r\\nThe [release tracker](https://github.com/pytorch/pytorch/issues/97272) should contain all relevant pull requests related to this release as well as links to related issues"}]}')}}]);
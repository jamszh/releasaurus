<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jamszh.github.io/releasaurus/releases</id>
    <title>Releasaurus Blog</title>
    <updated>2023-05-08T19:55:19.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jamszh.github.io/releasaurus/releases"/>
    <subtitle>Releasaurus Blog</subtitle>
    <icon>https://jamszh.github.io/releasaurus/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[v2.0.1-pytorch]]></title>
        <id>https://jamszh.github.io/releasaurus/releases/v2.0.1-pytorch</id>
        <link href="https://jamszh.github.io/releasaurus/releases/v2.0.1-pytorch"/>
        <updated>2023-05-08T19:55:19.000Z</updated>
        <summary type="html"><![CDATA[This release is meant to fix the following issues (regressions / silent correctness):]]></summary>
        <content type="html"><![CDATA[<p>This release is meant to fix the following issues (regressions / silent correctness):</p><ul><li>Fix <code>_canonical_mask</code> throws warning when bool masks passed as input to TransformerEncoder/TransformerDecoder (#96009, #96286) </li><li>Fix Embedding bag max_norm=-1 causes leaf Variable that requires grad is being used in an in-place operation #95980</li><li>Fix type hint for torch.Tensor.grad_fn, which can be a torch.autograd.graph.Node or None. #96804</li><li>Can’t convert float to int when the input is a scalar np.ndarray. #97696</li><li>Revisit torch._six.string_classes removal  #97863</li><li>Fix module backward pre-hooks to actually update gradient #97983</li><li>Fix load_sharded_optimizer_state_dict error on multi node #98063</li><li>Warn once for TypedStorage deprecation #98777</li><li>cuDNN V8 API, Fix incorrect use of emplace in the benchmark cache #97838</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="torchcompile">Torch.compile:<a href="#torchcompile" class="hash-link" aria-label="Direct link to Torch.compile:" title="Direct link to Torch.compile:">​</a></h3><ul><li>Add support for Modules with custom <strong>getitem</strong> method to torch.compile #97932</li><li>Fix improper guards with on list variables. #97862</li><li>Fix Sequential nn module with duplicated submodule #98880</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="distributed">Distributed:<a href="#distributed" class="hash-link" aria-label="Direct link to Distributed:" title="Direct link to Distributed:">​</a></h3><ul><li>Fix distributed_c10d's handling of custom backends #95072</li><li>Fix MPI backend not properly initialized #98545</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="nn_frontend">NN_frontend:<a href="#nn_frontend" class="hash-link" aria-label="Direct link to NN_frontend:" title="Direct link to NN_frontend:">​</a></h3><ul><li>Update Multi-Head Attention's doc string #97046</li><li>Fix incorrect behavior of <code>is_causal</code> paremeter for torch.nn.TransformerEncoderLayer.forward #97214</li><li>Fix error for SDPA on sm86 and sm89 hardware #99105</li><li>Fix nn.MultiheadAttention mask handling  #98375</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataloader">DataLoader:<a href="#dataloader" class="hash-link" aria-label="Direct link to DataLoader:" title="Direct link to DataLoader:">​</a></h3><ul><li>Fix regression for pin_memory recursion when operating on bytes #97737</li><li>Fix collation logic #97789 </li><li>Fix Ppotentially backwards incompatible change with DataLoader and is_shardable Datapipes #97287</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="mps">MPS:<a href="#mps" class="hash-link" aria-label="Direct link to MPS:" title="Direct link to MPS:">​</a></h3><ul><li>Fix LayerNorm crash when input is in float16 #96208</li><li>Add support for cumsum on int64 input  #96733</li><li>Fix issue with setting BatchNorm to non-trainable #98794</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="functorch">Functorch:<a href="#functorch" class="hash-link" aria-label="Direct link to Functorch:" title="Direct link to Functorch:">​</a></h3><ul><li>Fix Segmentation Fault for vmaped function accessing BatchedTensor.data #97237</li><li>Fix index_select support when dim is negative <a href="https://github.com/pytorch/pytorch/pull/97916" target="_blank" rel="noopener noreferrer">#97916</a></li><li>Improve docs for autograd.Function support #98020</li><li>Fix Exception thrown when running Migration guide example for jacrev #97746</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="releng">Releng:<a href="#releng" class="hash-link" aria-label="Direct link to Releng:" title="Direct link to Releng:">​</a></h3><ul><li>Fix Convolutions for CUDA-11.8 wheel builds #99451</li><li>Fix Import torchaudio + torch.compile crashes on exit #96231</li><li>Linux aarch64 wheels are missing the mkldnn+acl backend support  - <a href="https://github.com/pytorch/builder/commit/54931c264ed3e7346899f547a272c4329cc8933b" target="_blank" rel="noopener noreferrer">https://github.com/pytorch/builder/commit/54931c264ed3e7346899f547a272c4329cc8933b</a></li><li>Linux aarch64 torchtext 0.15.1 wheels are missing for aarch64_linux platform - <a href="https://github.com/pytorch/builder/issues/1375" target="_blank" rel="noopener noreferrer">https://github.com/pytorch/builder/issues/1375</a></li><li>Enable ROCm 5.4.2 manywheel and python 3.11 builds #99552</li><li>PyTorch cannot be installed at the same time as numpy in a conda env on osx-64 / Python 3.11 #97031</li><li>Illegal instruction (core dumped) on Raspberry Pi 4.0 8gb  - <a href="https://github.com/pytorch/builder/pull/1370" target="_blank" rel="noopener noreferrer">https://github.com/pytorch/builder/pull/1370</a></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="torchoptim">Torch.optim:<a href="#torchoptim" class="hash-link" aria-label="Direct link to Torch.optim:" title="Direct link to Torch.optim:">​</a></h3><ul><li>Fix fused AdamW causes NaN loss #95847</li><li>Fix Fused AdamW has worse loss than Apex and unfused AdamW for fp16/AMP #98620</li></ul><p>The <a href="https://github.com/pytorch/pytorch/issues/97272" target="_blank" rel="noopener noreferrer">release tracker</a> should contain all relevant pull requests related to this release as well as links to related issues</p>]]></content>
        <author>
            <name>drisspg</name>
            <uri>https://github.com/drisspg</uri>
        </author>
        <category label="pytorch" term="pytorch"/>
    </entry>
</feed>